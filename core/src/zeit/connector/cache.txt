Caches
======

Body cache
++++++++++

We are caching the bodies of resources. The cache removes objects a given time
after the last access, by default 30 days.

>>> import zeit.connector.cache
>>> cache = zeit.connector.cache.ResourceCache()

>>> cache.UPDATE_INTERVAL = 0.9


Validation
----------

For getting data from the cache, the cache needs the etag from the properties:

Initially the cache is empty and asking for a non  cached entry yields a
KeyError:

>>> cache.getData('some-id', 'etag1')
Traceback (most recent call last):
    ...
KeyError: "Object 'some-id' is not cached."


Set some data. `setData` returns either a StringIO or an open file handle. What
it returns depends on the size of the input data. For small data is returned as
StringIO:

>>> from io import BytesIO
>>> data = BytesIO(b'datadata/end of line.')
>>> f = cache.setData('some-id', data, 'etag1')
>>> f
<...BytesIO object at 0x...>
>>> f.read()
b'datadata/end of line.'
>>> f.close()

We can get the data also via `getData` now which also returns a StringIO for
small objects:

>>> f = cache.getData('some-id', 'etag1')
>>> f
<...BytesIO object at 0x...>
>>> f.close()

We have data in the cache. Since it's a small object it is stored as a
reference to a plain string:

>>> from zeit.connector.cache import get_storage_key
>>> cached = cache._data[get_storage_key('some-id')]
>>> cached
<zeit.connector.cache.Body object at 0x...>
>>> cached.data
b'datadata/end of line.'
>>> f = cached.open('r')
>>> f
<...BytesIO object at 0x...>
>>> f.read()
b'datadata/end of line.'
>>> f.close()

Also the access times are noted in the cache:

>>> last_access = cache._last_access_time[get_storage_key('some-id')]
>>> isinstance(last_access, (int, int))
True
>>> cache._access_time_to_ids[last_access]
<BTrees.OIBTree.OITreeSet object at 0x...>
>>> list(cache._access_time_to_ids[last_access])
[b'some-id']

When we now access getData the access time will be updated by at most one
count since less time than the update interval should have passed:

>>> f = cache.getData('some-id', 'etag1')
>>> f
<...BytesIO object at 0x...>
>>> f.close()
>>> cache._last_access_time[get_storage_key('some-id')] <= last_access + 1
True

Let's wait 1 second:

>>> import time
>>> time.sleep(1)

If we access now the time will be updated:

>>> f = cache.getData('some-id', 'etag1')
>>> f
<...BytesIO object at 0x...>
>>> f.close()
>>> new_access = cache._last_access_time[get_storage_key('some-id')]
>>> new_access > last_access
True

Also the the time to id mapping has been updated:

>>> list(cache._access_time_to_ids[last_access])
[]
>>> cache._access_time_to_ids[new_access]
<BTrees.OIBTree.OITreeSet object at 0x...>
>>> list(cache._access_time_to_ids[new_access])
[b'some-id']

Removal of cached bodies by time out
------------------------------------

Add another resource to the cache to see how resources are removed from the
cache:

>>> data = BytesIO(b'another text')
>>> cache.setData('another-id', data, 'etag1').close()

We now have two elements in the cache:

>>> sorted(get_storage_key(k) for k in cache._last_access_time.keys())
[b'another-id', b'some-id']

Now sleep another 4 second and see the `some-id` will be gone after sweeping:

>>> time.sleep(1)
>>> cache.sweep(4)
>>> f = cache.getData('another-id', 'etag1')
>>> f
<...BytesIO object at 0x...>
>>> f.close()
>>> sorted(get_storage_key(k) for k in cache._last_access_time.keys())
[b'another-id', b'some-id']

Still there ...

>>> time.sleep(1)
>>> cache.sweep(4)
>>> f = cache.getData('another-id', 'etag1')
>>> f
<...BytesIO object at 0x...>
>>> f.close()
>>> sorted(get_storage_key(k) for k in cache._last_access_time.keys())
[b'another-id', b'some-id']

Still there ...

>>> time.sleep(1)
>>> cache.sweep(4)
>>> f = cache.getData('another-id', 'etag1')
>>> f
<...BytesIO object at 0x...>
>>> f.close()
>>> sorted(get_storage_key(k) for k in cache._last_access_time.keys())
[b'another-id', b'some-id']

Now it's gone:

>>> time.sleep(1)
>>> cache.sweep(4)
>>> f = cache.getData('another-id', 'etag1')
>>> f
<...BytesIO object at 0x...>
>>> f.close()
>>> sorted(get_storage_key(k) for k in cache._last_access_time.keys())
[b'another-id']

We don't have any data stored for the key now:

>>> cache._data[get_storage_key(b'some-id')]
Traceback (most recent call last):
    ...
KeyError: ...


Large data handling
-------------------

For large objects we store a blob. What a large object is, is determined by the
buffer size:

>>> BUFFER_SIZE = zeit.connector.cache.Body().BUFFER_SIZE

Create data which is larger than that:


>>> large_data = 'Large' + ('Data' * BUFFER_SIZE)
>>> large_data = bytes(large_data.encode('utf-8'))
>>>
>>> f = cache.setData('some-id', BytesIO(large_data), 'etag1')
>>> f.read() == large_data
True
>>> f.close()

We can get the data also via `getData` which returns an open file handle:

>>> f = cache.getData('some-id', 'etag1')
>>> hasattr(f, 'read')
True
>>> f.close()

Internally a blob is created in this case:

>>> body = cache._data[get_storage_key('some-id')]
>>> body
<zeit.connector.cache.Body object at 0x...>
>>> body.data
<ZODB.blob.Blob object at 0x...>

When the transaction is commited we'll get a file directly from the blob
storage. Make the blob commited:

>>> import transaction
>>> transaction.commit()

We get the commited data now:

>>> f = cache.getData('some-id', 'etag1')
>>> f.read() == large_data
True
>>> f.close()

Transaction integration
-----------------------

When a resource is just read from the cache, no part of the cache needs to be
written to the database (given that no timeouts had to be updated).

Create a new cache and attach it to the database root:

>>> cache = zeit.connector.cache.ResourceCache()
>>> getRootFolder()['cache'] = cache
>>> transaction.commit()

Add an object to the cache and commit:

>>> data = BytesIO(b'Frodo went deep into Mordor.')
>>> cache.setData('mordor', data, 'ent').close()
>>> transaction.commit()

After commiting everything is "not changed" of course. Now get an the object
from the cache:

>>> f = cache.getData('mordor', 'ent')
>>> f.close()

All the cache parts are still not changed:

>>> cache._p_changed
False
>>> cache._data._p_changed
False
>>> cache._last_access_time._p_changed
False
>>> cache._access_time_to_ids._p_changed
False
>>> [s for s in cache._access_time_to_ids.values() if s._p_changed]
[]


Property Cache
++++++++++++++

We need to manually clear the key cache from previous tests runs due to
isolation problems:

>>> zeit.connector.cache.WebDAVPropertyKey._instances.clear()

The property cache stores all the webdav proprties:

>>> cache = zeit.connector.cache.PropertyCache()

Validate the interface:

>>> import zope.interface.verify
>>> zope.interface.verify.verifyObject(
...     zeit.connector.interfaces.IPersistentCache,
...     cache)
True

Test the methods:

>>> cache['id'] = {('ns', 'foo'): 'bar'}
>>> dict(cache['id'])
{<WebDAVPropertyKey ('ns', 'foo')>: 'bar'}
>>> dict(cache.get('id'))
{<WebDAVPropertyKey ('ns', 'foo')>: 'bar'}
>>> cache.get('foo', "don't have that")
"don't have that"

>>> 'id' in cache
True
>>> 'blafasel' in cache
False
>>> list(cache.keys())
[b'id']

>>> del cache['id']
>>> cache['id']
Traceback (most recent call last):
    ...
KeyError: 'id'

>>> cache.get('id') is None
True
>>> list(cache.keys())
[]

Note that there is actually still the entry in the cache, but marked as
deleted:

>>> list(cache.keys(include_deleted=True))
[b'id']

To really remove there is the remove method, which also works for "deleted"
keys:

>>> cache.remove('id')
>>> list(cache.keys(include_deleted=True))
[]

The property cache does some magic to prevent extensive memory consumption. The
keys in the cache *values* are rather few, maybe 200. So it keeps track of the
different keys and stores/returns references to already passed ones.

>>> key = ('ns', 'name')
>>> properties = {key: 'somevalue'}
>>> cache['id'] = properties

Store another property set with another instance of "key":

>>> key2 = ('ns', 'name')
>>> key == key2
True
>>> key is key2
False

>>> cache['otherid'] = {key2: 'othervalue'}

When we get the properties of 'otherid' back, the key2 is the same instance as
key:

>>> key2_back = list(cache['otherid'].keys())[0]
>>> key2_back == key2 == key
True
>>> key2_back is key2
False

We can also directly set keys on the property dict:

>>> cache['id'][('foo', 'bar')] = 'zoot'
>>> cache['id'][('foo', 'bar')]
'zoot'

Note that the key is also munged into a WebDAVPropertyKey:

>>> sorted(list(cache['id'].keys()))
[<WebDAVPropertyKey ('foo', 'bar')>, <WebDAVPropertyKey ('ns', 'name')>]

Removing also works directly:

>>> del cache['id'][('foo', 'bar')]

The cache keeps track of the used keys:

>>> import pprint
>>> pprint.pprint(zeit.connector.cache.WebDAVPropertyKey._instances)
{('foo', 'bar'): <WebDAVPropertyKey ('foo', 'bar')>,
 ('ns', 'foo'): <WebDAVPropertyKey ('ns', 'foo')>,
 ('ns', 'name'): <WebDAVPropertyKey ('ns', 'name')>}

When the a value is set to the cache which is equal to the value it alreay
stores, the new value is not updated. We verify this by setting a new value
which is equal but not the same:

>>> dict(cache['id'])
{<WebDAVPropertyKey ('ns', 'name')>: 'somevalue'}
>>> new_properties =  {('ns', 'name'): 'somevalue'}

Setting ``new_properties`` does not update the ``somevalue`` to unicode:

>>> cache['id'] = new_properties
>>> dict(cache['id'])
{<WebDAVPropertyKey ('ns', 'name')>: 'somevalue'}


Note that internally no dictionaries are stored but a special object which also
does conflict resolution:

>>> cache._storage[b'id']
<zeit.connector.cache.Properties object at 0x...>



Child name cache
++++++++++++++++

The childname cache just stores a mapping of unique id to a list of child
names:

>>> cache = zeit.connector.cache.ChildNameCache()
>>> cache['id'] = ['foo', 'bar', 'baz']

The data is returned as a ChildNames object which also sorts the ids:

>>> cache['id']
<zeit.connector.cache.ChildNames object at 0x...>
>>> list(cache['id'])
['bar', 'baz', 'foo']

When we remove things from the cache they're gone:

>>> del cache['id']
>>> cache['id']
Traceback (most recent call last):
    ...
KeyError: 'id'

>>> cache.get('id') is None
True

But actually the're just marked as deleted:

>>> cache._storage[b'id']
<zeit.connector.cache.ChildNames object at 0x...>
>>> list(cache._storage[b'id'])
[DeleteProperty]


When the a value is set to the cache which is equal to the value it alreay
stores, the new value is not updated. We verify this by setting a new value
which is equal but not the same:

>>> cache['id'] = ['foo', 'bar', 'baz']
>>> new_children =  ['foo', 'bar', 'baz']

Setting ``new_children`` does not update ``baz`` to unicode:

>>> cache['id'] = new_children
>>> list(cache['id'])
['bar', 'baz', 'foo']
